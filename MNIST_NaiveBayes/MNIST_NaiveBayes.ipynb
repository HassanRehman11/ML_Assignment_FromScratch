{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi2BzM2vyQF7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsfPMdC1ySgG"
      },
      "source": [
        "class NaiveBayes(object):\n",
        "\n",
        "    def train_data(self, x_train, y_train, smoothing=1000):\n",
        "        '''\n",
        "        This function will train the data\n",
        "        param: x_train -> features\n",
        "        param: y_train -> labels\n",
        "        params: smoothing -> to add into variance\n",
        "\n",
        "        '''\n",
        "        self.smoothing = smoothing\n",
        "        self.no_rows, self.x_features = x_train.shape #getting no of samples and no of features(here features are 28*28=784)\n",
        "        X_train = np.zeros([self.no_rows, self.x_features+1]) #making a mask for merging the features and label in one numpy array\n",
        "        X_train[:,:-1] = x_train \n",
        "        X_train[:,-1]=y_train\n",
        "\n",
        "        self.unique_classes=np.unique(X_train[:,-1]) # getting no of unique classes\n",
        "        self.no_classes=len(self.unique_classes)            \n",
        "        np.random.shuffle(X_train) # shuffling the data to avoid biasness\n",
        "\n",
        "        '''\n",
        "        Creating the mask to calculate mean and variance\n",
        "        of individual pixels and individual classes.\n",
        "        It will generate 10x784 size of array\n",
        "        '''\n",
        "        self.pixel_mean_value=np.zeros([self.no_classes,self.x_features]) \n",
        "        self.pixel_variance_value=np.zeros([self.no_classes,self.x_features])\n",
        "        self.prior_prob=[] # for storing the individual prior probability of classes\n",
        "\n",
        "        self.prior = {}\n",
        "        for e in self.unique_classes:\n",
        "            class_occurance=X_train[X_train[:,-1]==e] # getting all the arrays where class == e\n",
        "            class_occurance=class_occurance[:,:-1]\n",
        "            self.prior[e] = len(class_occurance)/len(X_train)\n",
        "            self.prior_prob.append(len(class_occurance)/len(X_train))\n",
        "            self.pixel_mean_value[int(e),:]=class_occurance.mean(axis=0)\n",
        "            self.pixel_variance_value[int(e),:]=class_occurance.var(axis=0)\n",
        "\n",
        "        '''\n",
        "        Here we are adding smoothing to variance as variance\n",
        "        will be in denominator so to avoid infinte error\n",
        "\n",
        "        I take it thousand as it gives good accuracy on it\n",
        "        '''\n",
        "        self.pixel_variance_value=self.pixel_variance_value+self.smoothing\n",
        "\n",
        "        return (self.prior) #it returns the prior probability of individual class in dictionary\n",
        "    def predict_data(self, x_test):\n",
        "        '''\n",
        "        param: x_test -> feature set to predict\n",
        "\n",
        "        This function as the name says predicts the data\n",
        "        it takes testing data as input.\n",
        "        Gaussian Distribution is used as we have multiple classes\n",
        "        You can look mathematical formula her:\n",
        "        https://www.gstatic.com/education/formulas2/397133473/en/normal_distribution.svg\n",
        "        '''\n",
        "        self.predicted = []\n",
        "        for i in range(x_test.shape[0]):\n",
        "            posteriors = []\n",
        "            for j in range(self.no_classes):\n",
        "                #>>>>>>>>>>>>>>>> Gausian Distribution <<<<<<<<<<<<<\n",
        "                numerator=np.exp(-((x_test[i]-self.pixel_mean_value[j])**2)/(2*self.pixel_variance_value[j])) \n",
        "                denominator=np.sqrt(2*np.pi*(self.pixel_variance_value[j]))\n",
        "                prob_xc=numerator/denominator\n",
        "                #>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "                posterior=np.sum(np.log(prob_xc)+np.log(self.prior_prob[j]))\n",
        "                posteriors.append(posterior)\n",
        "            self.predicted.append(np.argmax(posteriors)) # Position with highest ratio will be the predicted class\n",
        "        return self.predicted\n",
        "    \n",
        "    def accuracy(self, predicted, y_test):\n",
        "        \n",
        "        '''\n",
        "        param: predicted -> It is the list that will be generated by predict function\n",
        "        param: y_test -> labels of testing data\n",
        "\n",
        "        The function will give the accuracy on basis correctly predicted divided by total data in test\n",
        "        '''\n",
        "        count = 0\n",
        "        if(len(predicted)==len(y_test)):\n",
        "            for i in range(len(predicted)):\n",
        "                if(predicted[i]==y_test[i]):\n",
        "                    count=count+1\n",
        "            return count/len(y_test)\n",
        "        else:\n",
        "            raise Exception(\"Length of two arrays did not match\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfu-jD6uDgQo"
      },
      "source": [
        "# MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1tBMnL_2LcJ"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train=x_train.reshape(60000,784)\n",
        "x_test=x_test.reshape(10000,784)\n",
        "classifier = NaiveBayes()\n",
        "clf = classifier.train_data(x_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOiE14Bb2kN-"
      },
      "source": [
        "pred = classifier.predict_data(x_test)\n",
        "accuracy = classifier.accuracy(pred, y_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zprV4AB3ndA",
        "outputId": "7b7d293e-1bc9-4e09-ad42-50f128f148f3"
      },
      "source": [
        "print(f\"Accuracy by NaiveBayes classifier on MNIST is: {accuracy}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy by NaiveBayes classifier on MNIST is: 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9AfHbq-7T29",
        "outputId": "4af90ce0-a553-4a3e-8744-0a0a26abdb52"
      },
      "source": [
        "print(f\"Prior Probability of each class is:\\n {clf}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior Probability of each class is:\n",
            " {0.0: 0.09871666666666666, 1.0: 0.11236666666666667, 2.0: 0.0993, 3.0: 0.10218333333333333, 4.0: 0.09736666666666667, 5.0: 0.09035, 6.0: 0.09863333333333334, 7.0: 0.10441666666666667, 8.0: 0.09751666666666667, 9.0: 0.09915}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plBUWq7NEN8w"
      },
      "source": [
        "# MNIST Data by Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dytIljtrERoA",
        "outputId": "4a0685b7-54b3-40ed-d8a3-d8a4414bbe42"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EKJpyKpFVBA",
        "outputId": "ed098b4e-8949-489a-c75a-d4d0245876a1"
      },
      "source": [
        "!kaggle competitions download -c digit-recognizer\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/6.09M [00:00<?, ?B/s]\n",
            "100% 6.09M/6.09M [00:00<00:00, 55.6MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 74.8MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 55% 5.00M/9.16M [00:00<00:00, 47.8MB/s]\n",
            "100% 9.16M/9.16M [00:00<00:00, 55.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zu_C2DbFoPE",
        "outputId": "aeb82355-7f0b-4ddf-bd58-86891003fd25"
      },
      "source": [
        "!unzip test.csv.zip\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbFBX0E2FxJO"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBfF2BfSGJWv"
      },
      "source": [
        "y_train = np.array(train['label'])\n",
        "train.drop('label',axis='columns',inplace=True)\n",
        "x_train = np.array(train)\n",
        "x_test = np.array(test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPYq2vpVGLZg"
      },
      "source": [
        "classifier = NaiveBayes()\n",
        "clf = classifier.train_data(x_train, y_train)\n",
        "pred = classifier.predict_data(x_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzKUEvj8Gddu",
        "outputId": "c755f2a4-5e22-4765-8728-3d47bc6cbbda"
      },
      "source": [
        "print(f\"Prior Probability of each class is:\\n {clf}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior Probability of each class is:\n",
            " {0.0: 0.09838095238095237, 1.0: 0.11152380952380953, 2.0: 0.09945238095238096, 3.0: 0.1035952380952381, 4.0: 0.09695238095238096, 5.0: 0.09035714285714286, 6.0: 0.0985, 7.0: 0.10478571428571429, 8.0: 0.09673809523809523, 9.0: 0.09971428571428571}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F3pnuRpHhP1"
      },
      "source": [
        "'''\n",
        "Submission csv\n",
        "'''\n",
        "submission = pd.DataFrame({\n",
        "    \"ImageId\": list(range(1,len(pred)+1)),\n",
        "    \"Label\": pred\n",
        "})\n",
        "submission.to_csv(\"submission.csv\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md3pTdbuJEiC"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y80EOVF6KHcF"
      },
      "source": [
        ""
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f5yzsLkKKrU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}